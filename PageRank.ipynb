{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01320779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#networkx is used to create and process graphs.\n",
    "#NetworkXError handles any graph-related errors\n",
    "import networkx as nx\n",
    "from networkx.exception import NetworkXError\n",
    "\n",
    "def pagerank(G, alpha=0.85, personalization=None,  #G → input graph alpha → damping factor tol → stopping condition\n",
    "             max_iter=100, tol=1.0e-6, nstart=None, weight='weight',\n",
    "             dangling=None):     #start → initial rank values dangling → nodes with no outgoing links\n",
    "\n",
    "    if len(G) == 0:\n",
    "        return {}\n",
    "\n",
    "    if not G.is_directed():\n",
    "        D = G.to_directed()   #PageRank works on directed graphs, so if it's undirected, convert it.\n",
    "    else:\n",
    "        D = G\n",
    "\n",
    "    # Convert graph to stochastic form\n",
    "    W = nx.stochastic_graph(D, weight=weight)  #Converts graph into probability transition format (each row sums to 1).\n",
    "    N = W.number_of_nodes()    #Stores total number of nodes.\n",
    "\n",
    "    # Initialize rank vector\n",
    "    if nstart is None:\n",
    "        x = dict.fromkeys(W, 1.0 / N)  # if no initial values, assign equal rank 1/N to every node.\n",
    "    else:\n",
    "        s = float(sum(nstart.values()))\n",
    "        x = {k: v / s for k, v in nstart.items()} #If initial values are provided, normalize them so total = 1.\n",
    "\n",
    "    # Personalization vector\n",
    "    if personalization is None:\n",
    "        p = dict.fromkeys(W, 1.0 / N)  #If no personalization, use equal probability for all nodes\n",
    "    else:\n",
    "        missing = set(G) - set(personalization)  #Checks if any node is missing from personalization.\n",
    "        if missing:\n",
    "            raise NetworkXError(f\"Personalization missing nodes: {missing}\")\n",
    "        s = float(sum(personalization.values()))    #Normalize personalization values.\n",
    "        p = {k: v / s for k, v in personalization.items()}\n",
    "\n",
    "    # Dangling nodes handling\n",
    "    if dangling is None:\n",
    "        dangling_weights = p   #If no dangling vector given, use personalization vector for it.\n",
    "    else:\n",
    "        missing = set(G) - set(dangling)   #Ensures all nodes exist in dangling dictionary.\n",
    "        if missing:\n",
    "            raise NetworkXError(f\"Dangling dictionary missing nodes: {missing}\")\n",
    "        s = float(sum(dangling.values()))\n",
    "        dangling_weights = {k: v / s for k, v in dangling.items()}  \n",
    " \n",
    "    dangling_nodes = [n for n in W if W.out_degree(n, weight=weight) == 0.0]\n",
    "    #Finds nodes that have zero outgoing links.\n",
    "\n",
    "    # Power iteration\n",
    "    for _ in range(max_iter):\n",
    "        xlast = x.copy()     #Save previous rank values for convergence check.\n",
    "        x = dict.fromkeys(xlast.keys(), 0)     #Reset rank for new iteration.\n",
    "        danglesum = alpha * sum(xlast[n] for n in dangling_nodes)  #Total rank lost due to dangling nodes, redistributed later.\n",
    " \n",
    "        for n in x:\n",
    "            for nbr in W[n]:                  # Distribute rank from node n to its neighbors nbr.\n",
    "                x[nbr] += alpha * xlast[n] * W[n][nbr][weight]\n",
    "            x[n] += danglesum * dangling_weights[n] + (1.0 - alpha) * p[n]\n",
    "\n",
    "        # Check convergence (L1 norm)\n",
    "        err = sum(abs(x[n] - xlast[n]) for n in x)  #Compute difference between new and old ranks.\n",
    "        if err < N * tol:\n",
    "            return x            #If difference is very small → stop early and return result.\n",
    "\n",
    "    raise NetworkXError(f\"PageRank failed to converge in {max_iter} iterations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5defe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.02805009581317142, 1: 0.012149551779168336, 2: 0.012577178556923042, 3: 0.013368320767324294, 4: 0.01235902999867519, 5: 0.012760429829180102, 6: 0.013166434313000996, 7: 0.013370931927890796, 8: 0.013162439327920817, 9: 0.01297475828042739, 10: 0.013377296141376987, 11: 0.012758619341896413, 12: 0.012963140909757203, 13: 0.012790074184971034, 14: 0.01296667038759297, 15: 0.012181283050371071, 16: 0.012559017759709828, 17: 0.013570227254980078, 18: 0.012574796322044536, 19: 0.012365437691344015, 20: 0.013569631650820396, 21: 0.01295552964699519, 22: 0.01315110285730655, 23: 0.013568074677829023, 24: 0.01256989160799764, 25: 0.013357591275027697, 26: 0.013569210387615917, 27: 0.01316864141035763, 28: 0.01257419226084101, 29: 0.012756160509648055, 30: 0.012963024587279057, 31: 0.013162439327920817, 32: 0.012973829944259026, 33: 0.01295589739101076, 34: 0.013357591275027697, 35: 0.01254614051508213, 36: 0.012958335403099566, 37: 0.012386081360350758, 38: 0.013168917400840523, 39: 0.01317490459667052, 40: 0.013156701654736074, 41: 0.01256625869478752, 42: 0.02770325035182939, 43: 0.027346702676856266, 44: 0.02687241088655, 45: 0.02654095118759415, 46: 0.026007266430633093, 47: 0.025519968843784716, 48: 0.025273993857845563, 49: 0.025155486363255132, 50: 0.02464204257000728, 51: 0.02427627827526539, 52: 0.023978237547071592, 53: 0.02360385380726844, 54: 0.023162276740665084, 55: 0.022884787709812275, 56: 0.022713097059867966, 57: 0.02236436230596983, 58: 0.021725036042968607, 59: 0.021574115269525213}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# In PageRank, damping factor (α) represents the probability that a user will:\n",
    "# continue clicking the next link → α probability\n",
    "#randomly jump to any other page → (1 − α) probability\n",
    "\n",
    "G = nx.barabasi_albert_graph(60, 41)\n",
    "#Creates a graph with 60 nodes, each connecting to 41 others.\n",
    "pr = pagerank(G, alpha=0.4)    #Runs PageRank with damping factor 0.4 and prints scores.\n",
    "\n",
    "print(pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b0560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
